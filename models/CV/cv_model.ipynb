{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13572165,"sourceType":"datasetVersion","datasetId":8621897}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Trading Chart Classification with ResNet50 - Baseline Model\n# Based on baseline.py with Kaggle dataset integration\n!pip install timm torch torchvision tqdm pandas pillow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:14.745475Z","iopub.execute_input":"2025-11-17T02:38:14.746564Z","iopub.status.idle":"2025-11-17T02:38:18.203992Z","shell.execute_reply.started":"2025-11-17T02:38:14.746534Z","shell.execute_reply":"2025-11-17T02:38:18.203192Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.36.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import argparse\nimport os\nimport time\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.205962Z","iopub.execute_input":"2025-11-17T02:38:18.206247Z","iopub.status.idle":"2025-11-17T02:38:18.211900Z","shell.execute_reply.started":"2025-11-17T02:38:18.206210Z","shell.execute_reply":"2025-11-17T02:38:18.211161Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# ----------------- CONFIG -----------------\nMODEL_DIR = \"models\"  # Will be created in Kaggle working directory\nLABELS_CSV = \"/kaggle/input/labels.csv\"\nIMAGES_ROOT = \"/kaggle/input/SBER_images(2025-06-01 - 2025-10-01)\"\n\n# Memory-optimized hyperparameters\nBATCH_SIZE = 4  # Much smaller batch size\nGRADIENT_ACCUMULATION_STEPS = 8  # Accumulate gradients over multiple batches\nNUM_EPOCHS = 30\nLEARNING_RATE_BACKBONE = 1e-4  # More conservative than your 5e-4\nLEARNING_RATE_CLASSIFIER = 3e-4  # Less aggressive than your 1e-3\nWEIGHT_DECAY = 1e-4  # Lighter than your 5e-4\nVAL_FRAC = 0.2\nSEED = 42\nNUM_WORKERS = 2  # Reduced workers to save memory","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.212680Z","iopub.execute_input":"2025-11-17T02:38:18.213498Z","iopub.status.idle":"2025-11-17T02:38:18.229987Z","shell.execute_reply.started":"2025-11-17T02:38:18.213468Z","shell.execute_reply":"2025-11-17T02:38:18.229247Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Device setup\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Device: {DEVICE}')\nif DEVICE.type == 'cuda':\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.231773Z","iopub.execute_input":"2025-11-17T02:38:18.232113Z","iopub.status.idle":"2025-11-17T02:38:18.246036Z","shell.execute_reply.started":"2025-11-17T02:38:18.232090Z","shell.execute_reply":"2025-11-17T02:38:18.245228Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nGPU: Tesla T4\nMemory: 14.7 GB\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Dataset class from baseline.py\nclass CVImageDataset(Dataset):\n    def __init__(self, df, transform=None, to_rgb=True):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.to_rgb = to_rgb\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        p = self.df.loc[idx, 'path']\n        img = Image.open(p)\n        if self.to_rgb:\n            img = img.convert('RGB')\n        x = self.transform(img) if self.transform is not None else transforms.ToTensor()(img)\n        y = int(self.df.loc[idx, 'label_idx'])\n        return x, torch.tensor(y, dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.246643Z","iopub.execute_input":"2025-11-17T02:38:18.246798Z","iopub.status.idle":"2025-11-17T02:38:18.260414Z","shell.execute_reply.started":"2025-11-17T02:38:18.246786Z","shell.execute_reply":"2025-11-17T02:38:18.259700Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def make_dataloaders(labels_csv=LABELS_CSV, images_root=IMAGES_ROOT, batch_size=BATCH_SIZE, \n                    subset=None, val_frac=VAL_FRAC, num_workers=NUM_WORKERS, seed=SEED):\n    df = pd.read_csv(labels_csv)\n    df['label'] = df['label'].astype(str).str.strip().str.lower()\n    label_map = {lab: i for i, lab in enumerate(sorted(df['label'].unique()))}\n    df['label_idx'] = df['label'].map(label_map)\n    df['path'] = df['filename'].apply(lambda x: os.path.join(images_root, x))\n\n    if subset is not None and subset > 0:\n        df = df.sample(n=min(subset, len(df)), random_state=seed).reset_index(drop=True)\n\n    # MISSING: Split the data into train and validation sets\n    train_df, val_df = train_test_split(\n        df, test_size=val_frac, stratify=df['label_idx'], \n        random_state=seed, shuffle=True\n    )\n\n    # Smart preprocessing for chart images - maintain aspect ratio and key features\n    train_transform = transforms.Compose([\n        transforms.Resize((512, 512)),  # Larger than 224x224 but smaller than original\n        transforms.ToTensor(),\n    ])\n    \n    val_transform = transforms.Compose([\n        transforms.Resize((512, 512)),\n        transforms.ToTensor(),\n    ])\n\n    # Create datasets WITH transforms (don't overwrite these!)\n    train_ds = CVImageDataset(train_df, transform=train_transform, to_rgb=True)\n    val_ds = CVImageDataset(val_df, transform=val_transform, to_rgb=True)\n\n    # REMOVE these lines - they overwrite the datasets with transforms!\n    # train_ds = CVImageDataset(train_df, to_rgb=True)\n    # val_ds = CVImageDataset(val_df, to_rgb=True)\n\n    counts = train_df['label_idx'].value_counts().sort_index().values\n    counts = np.array([max(c, 1) for c in counts], dtype=float)\n    class_weights = 1.0 / counts\n    sample_weights = train_df['label_idx'].map(lambda x: class_weights[int(x)]).values\n    sample_weights = torch.DoubleTensor(sample_weights)\n    from torch.utils.data import WeightedRandomSampler\n    sampler = WeightedRandomSampler(\n        sample_weights, \n        num_samples=len(sample_weights), \n        replacement=True\n    )\n\n    train_loader = DataLoader(\n        train_ds, \n        batch_size=batch_size, \n        sampler=sampler,\n        num_workers=num_workers, \n        pin_memory=True,\n        drop_last=True\n    )\n    \n    val_loader = DataLoader(\n        val_ds, \n        batch_size=batch_size, \n        shuffle=False, \n        num_workers=num_workers, \n        pin_memory=True\n    )\n\n    meta = {\n        'label_map': label_map, \n        'train_len': len(train_ds), \n        'val_len': len(val_ds),\n        'class_counts': dict(df['label_idx'].value_counts().sort_index())\n    }\n    return train_loader, val_loader, meta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.261103Z","iopub.execute_input":"2025-11-17T02:38:18.261444Z","iopub.status.idle":"2025-11-17T02:38:18.271435Z","shell.execute_reply.started":"2025-11-17T02:38:18.261429Z","shell.execute_reply":"2025-11-17T02:38:18.270920Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def create_model(num_classes, device):\n    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n    in_feat = model.fc.in_features\n    \n    model.fc = nn.Sequential(\n        nn.Dropout(0.3),\n        nn.Linear(in_feat, 1024),\n        nn.BatchNorm1d(1024),\n        nn.ReLU(inplace=True),\n        nn.Dropout(0.2),\n        nn.Linear(1024, 512),\n        nn.BatchNorm1d(512),\n        nn.ReLU(inplace=True),\n        nn.Dropout(0.1),\n        nn.Linear(512, num_classes)\n    )\n    \n    for m in model.fc.modules():\n        if isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n    \n    return model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.272188Z","iopub.execute_input":"2025-11-17T02:38:18.272470Z","iopub.status.idle":"2025-11-17T02:38:18.289428Z","shell.execute_reply.started":"2025-11-17T02:38:18.272445Z","shell.execute_reply":"2025-11-17T02:38:18.288842Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Training functions from baseline.py\ndef train_epoch(model, train_loader, criterion, optimizer, device, accumulation_steps=4):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    optimizer.zero_grad()\n    \n    for i, (xb, yb) in enumerate(train_loader):\n        xb, yb = xb.to(device), yb.to(device)\n        \n        outputs = model(xb)\n        loss = criterion(outputs, yb) / accumulation_steps\n        loss.backward()\n        \n        if (i + 1) % accumulation_steps == 0:\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            optimizer.zero_grad()\n        \n        running_loss += loss.item() * xb.size(0) * accumulation_steps\n        _, predicted = outputs.max(1)\n        total += yb.size(0)\n        correct += predicted.eq(yb).sum().item()\n    \n    if len(train_loader) % accumulation_steps != 0:\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        optimizer.zero_grad()\n    \n    train_loss = running_loss / total\n    train_acc = correct / total\n    return train_loss, train_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.290048Z","iopub.execute_input":"2025-11-17T02:38:18.290236Z","iopub.status.idle":"2025-11-17T02:38:18.304634Z","shell.execute_reply.started":"2025-11-17T02:38:18.290217Z","shell.execute_reply":"2025-11-17T02:38:18.303927Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def validate(model, val_loader, criterion, device):\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            outputs = model(xb)\n            loss = criterion(outputs, yb)\n            \n            val_loss += loss.item() * xb.size(0)\n            _, predicted = outputs.max(1)\n            total += yb.size(0)\n            correct += predicted.eq(yb).sum().item()\n    \n    val_loss /= total\n    val_acc = correct / total\n    return val_loss, val_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.305460Z","iopub.execute_input":"2025-11-17T02:38:18.305725Z","iopub.status.idle":"2025-11-17T02:38:18.323452Z","shell.execute_reply.started":"2025-11-17T02:38:18.305709Z","shell.execute_reply":"2025-11-17T02:38:18.322938Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Plotting functions from baseline.py\ndef plot_training_history(train_losses, val_accs, train_accs):\n    plt.figure(figsize=(15, 5))\n    \n    plt.subplot(1, 3, 1)\n    plt.plot(train_losses)\n    plt.title('Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    \n    plt.subplot(1, 3, 2)\n    plt.plot(train_accs, label='Train')\n    plt.plot(val_accs, label='Validation')\n    plt.title('Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.subplot(1, 3, 3)\n    plt.plot(val_accs)\n    plt.title('Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.axhline(y=1/3, color='r', linestyle='--', label='Random (33%)')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig(f'{MODEL_DIR}/training_history.png', dpi=300, bbox_inches='tight')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.325462Z","iopub.execute_input":"2025-11-17T02:38:18.325657Z","iopub.status.idle":"2025-11-17T02:38:18.340946Z","shell.execute_reply.started":"2025-11-17T02:38:18.325644Z","shell.execute_reply":"2025-11-17T02:38:18.340281Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def plot_confusion_matrix(model, val_loader, device, label_map):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            outputs = model(xb)\n            _, preds = outputs.max(1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(yb.cpu().numpy())\n    \n    cm = confusion_matrix(all_labels, all_preds)\n    class_names = [k for k, v in sorted(label_map.items(), key=lambda x: x[1])]\n    \n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.colorbar()\n    tick_marks = np.arange(len(class_names))\n    plt.xticks(tick_marks, class_names, rotation=45)\n    plt.yticks(tick_marks, class_names)\n    \n    thresh = cm.max() / 2.\n    for i, j in np.ndindex(cm.shape):\n        plt.text(j, i, format(cm[i, j], 'd'),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    \n    plt.tight_layout()\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.savefig(f'{MODEL_DIR}/confusion_matrix.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    print(\"\\nClassification Report:\")\n    print(classification_report(all_labels, all_preds, target_names=class_names))\n    \n    return cm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.341539Z","iopub.execute_input":"2025-11-17T02:38:18.341718Z","iopub.status.idle":"2025-11-17T02:38:18.355068Z","shell.execute_reply.started":"2025-11-17T02:38:18.341704Z","shell.execute_reply":"2025-11-17T02:38:18.354244Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Your exact training function\ndef train(train_loader, val_loader, model, device, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, label_map=None):\n    save_path = f'{MODEL_DIR}/best_cv_model.pth'\n    os.makedirs(MODEL_DIR, exist_ok=True)\n    \n    class FocalLoss(nn.Module):\n        def __init__(self, alpha=1, gamma=2, reduction='mean'):\n            super().__init__()\n            self.alpha = alpha\n            self.gamma = gamma\n            self.reduction = reduction\n            \n        def forward(self, inputs, targets):\n            ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n            pt = torch.exp(-ce_loss)\n            focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n            \n            if self.reduction == 'mean':\n                return focal_loss.mean()\n            elif self.reduction == 'sum':\n                return focal_loss.sum()\n            else:\n                return focal_loss\n    \n    criterion = FocalLoss(gamma=2.0)\n    \n    backbone_params = []\n    classifier_params = []\n    \n    for name, param in model.named_parameters():\n        if 'fc' in name:\n            classifier_params.append(param)\n        else:\n            backbone_params.append(param)\n    \n    optimizer = torch.optim.AdamW([\n        {'params': backbone_params, 'lr': LEARNING_RATE_BACKBONE},\n        {'params': classifier_params, 'lr': LEARNING_RATE_CLASSIFIER}\n    ], weight_decay=WEIGHT_DECAY)\n    \n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n        optimizer, T_0=10, T_mult=2, eta_min=1e-6\n    )\n    \n    best_val_acc = 0.0\n    patience_counter = 0\n    max_patience = 12\n    \n    train_losses = []\n    train_accs = []\n    val_accs = []\n    \n    for epoch in range(epochs):\n        start_time = time.time()\n        \n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = validate(model, val_loader, criterion, device)\n        \n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n        val_accs.append(val_acc)\n        \n        scheduler.step()\n        \n        epoch_time = time.time() - start_time\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        print(f\"Epoch {epoch+1}/{epochs}  time={epoch_time:.1f}s  \"\n              f\"train_loss={train_loss:.4f}  train_acc={train_acc:.3f}  \"\n              f\"val_acc={val_acc:.3f}  lr={current_lr:.2e}\")\n        \n        if val_acc > best_val_acc + 0.001:\n            best_val_acc = val_acc\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'val_acc': val_acc,\n                'train_acc': train_acc\n            }, save_path)\n            patience_counter = 0\n            print(f\"✓ New best! Val accuracy: {val_acc:.4f}\")\n        else:\n            patience_counter += 1\n            print(f\"  No improvement ({patience_counter}/{max_patience})\")\n        \n        if patience_counter >= max_patience:\n            print(f\"Early stopping at epoch {epoch + 1}\")\n            break\n    \n    print(f'Training finished. Best validation accuracy: {best_val_acc:.4f}')\n    \n    plot_training_history(train_losses, val_accs, train_accs)\n    \n    print(\"\\nGenerating confusion matrix...\")\n    model.load_state_dict(torch.load(save_path)['model_state_dict'])\n    plot_confusion_matrix(model, val_loader, device, label_map)\n    \n    return best_val_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.355775Z","iopub.execute_input":"2025-11-17T02:38:18.355976Z","iopub.status.idle":"2025-11-17T02:38:18.376512Z","shell.execute_reply.started":"2025-11-17T02:38:18.355962Z","shell.execute_reply":"2025-11-17T02:38:18.375931Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Debug: Check if files exist\nimport os\nprint(f\"LABELS_CSV path: {LABELS_CSV}\")\nprint(f\"File exists: {os.path.exists(LABELS_CSV)}\")\n\nprint(f\"IMAGES_ROOT path: {IMAGES_ROOT}\")\nprint(f\"Directory exists: {os.path.exists(IMAGES_ROOT)}\")\n\n# List contents of the input directory\ninput_dir = \"/kaggle/input\"\nif os.path.exists(input_dir):\n    print(f\"Contents of {input_dir}:\")\n    for item in os.listdir(input_dir):\n        print(f\"  {item}\")\n        \n    sber_dir = \"/kaggle/input/sber0601-1001\"\n    if os.path.exists(sber_dir):\n        print(f\"Contents of {sber_dir}:\")\n        for item in os.listdir(sber_dir):\n            print(f\"  {item}\")\n\n\n# Load data and create dataloaders\nprint(\"Loading data...\")\ntrain_loader, val_loader, meta = make_dataloaders(\n    labels_csv=LABELS_CSV, \n    images_root=IMAGES_ROOT,\n    batch_size=BATCH_SIZE, \n    num_workers=NUM_WORKERS\n)\n\nprint('Label map:', meta['label_map'])\nprint(f'Train samples: {meta[\"train_len\"]}, Val samples: {meta[\"val_len\"]}')\nprint(f'Class counts: {meta[\"class_counts\"]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.377107Z","iopub.execute_input":"2025-11-17T02:38:18.377311Z","iopub.status.idle":"2025-11-17T02:38:18.541238Z","shell.execute_reply.started":"2025-11-17T02:38:18.377292Z","shell.execute_reply":"2025-11-17T02:38:18.540591Z"}},"outputs":[{"name":"stdout","text":"LABELS_CSV path: /kaggle/input/labels.csv\nFile exists: True\nIMAGES_ROOT path: /kaggle/input/SBER_images(2025-06-01 - 2025-10-01)\nDirectory exists: True\nContents of /kaggle/input:\n  SBER_images(2025-06-01 - 2025-10-01)\n  labels.csv\nLoading data...\nLabel map: {'down': 0, 'flat': 1, 'up': 2}\nTrain samples: 21651, Val samples: 5413\nClass counts: {0: 8870, 1: 6061, 2: 12133}\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Create model\nmodel = create_model(num_classes=len(meta['label_map']), device=DEVICE)\nprint(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")\n\n# Clear GPU cache\ntorch.cuda.empty_cache()\n\n# Then move to GPU\nmodel = model.to(DEVICE)\nprint(f\"GPU memory after moving to GPU: {torch.cuda.memory_allocated()/1024**3:.2f} GB used\")\nprint(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")\nprint(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:18.541995Z","iopub.execute_input":"2025-11-17T02:38:18.542299Z","iopub.status.idle":"2025-11-17T02:38:20.213301Z","shell.execute_reply.started":"2025-11-17T02:38:18.542280Z","shell.execute_reply":"2025-11-17T02:38:20.212512Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 166MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Model has 26,135,619 parameters\nGPU memory after moving to GPU: 0.10 GB used\nModel has 26,135,619 parameters\nTrainable parameters: 26,135,619\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# Train the model\nbest_acc = train(\n    train_loader, \n    val_loader, \n    model, \n    DEVICE, \n    epochs=NUM_EPOCHS,\n    batch_size=BATCH_SIZE,\n    label_map=meta['label_map']\n)\n\nprint(f'\\nFinal best validation accuracy: {best_acc:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T02:38:20.214197Z","iopub.execute_input":"2025-11-17T02:38:20.214539Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30  time=1201.6s  train_loss=0.5963  train_acc=0.395  val_acc=0.471  lr=9.76e-05\n✓ New best! Val accuracy: 0.4715\n","output_type":"stream"}],"execution_count":null}]}