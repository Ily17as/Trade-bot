{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de52fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Shared inference utilities extracted from the original notebook.\n",
    "\n",
    "This module centralizes the ML, CV, and optional RL inference steps that were\n",
    "previously defined inside ``app/inference_pipeline.ipynb`` so that they can be\n",
    "imported and reused without executing notebook cells.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from functools import lru_cache\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from dotenv import load_dotenv\n",
    "from tinkoff.invest import CandleInterval, Client\n",
    "\n",
    "try:  # ML\n",
    "    import xgboost as xgb\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    xgb = None  # type: ignore\n",
    "\n",
    "try:  # CV\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from torchvision import transforms\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    torch = None  # type: ignore\n",
    "    nn = None  # type: ignore\n",
    "    transforms = None  # type: ignore\n",
    "\n",
    "try:  # CV backbone\n",
    "    import timm\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    timm = None  # type: ignore\n",
    "\n",
    "try:  # Candle rendering\n",
    "    import mplfinance as mpf\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    mpf = None  # type: ignore\n",
    "    plt = None  # type: ignore\n",
    "\n",
    "from RL import build_feature_frame\n",
    "from RL.agent import RLAgent\n",
    "from RL.env import PortfolioState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3b328b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "DEFAULT_TOKEN = os.getenv(\"TINKOFF_TOKEN\")\n",
    "DEFAULT_TZ = pytz.timezone(\"Europe/Moscow\")\n",
    "DEFAULT_TIMEFRAME = CandleInterval.CANDLE_INTERVAL_5_MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ce68445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tinkoff_candles(\n",
    "    token: str,\n",
    "    ticker: str,\n",
    "    days: int = 1,\n",
    "    interval: CandleInterval = DEFAULT_TIMEFRAME,\n",
    "    tz: pytz.BaseTzInfo = DEFAULT_TZ,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Download OHLCV candles from the Tinkoff Invest API.\"\"\"\n",
    "\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TINKOFF_TOKEN is required to fetch candles\")\n",
    "\n",
    "    from tinkoff.invest.services import InstrumentsService  # lazy import\n",
    "    from tinkoff.invest.utils import now\n",
    "\n",
    "    with Client(token) as client:\n",
    "        instruments: InstrumentsService = client.instruments\n",
    "        shares = instruments.shares().instruments\n",
    "        figi: Optional[str] = None\n",
    "        for share in shares:\n",
    "            if share.ticker.upper() == ticker.upper():\n",
    "                figi = share.figi\n",
    "                break\n",
    "        if not figi:\n",
    "            raise RuntimeError(f\"FIGI for {ticker} not found\")\n",
    "\n",
    "        end = now()\n",
    "        start = end - timedelta(days=days)\n",
    "        candles = client.get_all_candles(figi=figi, from_=start, to=end, interval=interval)\n",
    "\n",
    "        data = [\n",
    "            {\n",
    "                \"time\": candle.time.astimezone(tz),\n",
    "                \"open\": candle.open.units + candle.open.nano / 1e9,\n",
    "                \"high\": candle.high.units + candle.high.nano / 1e9,\n",
    "                \"low\": candle.low.units + candle.low.nano / 1e9,\n",
    "                \"close\": candle.close.units + candle.close.nano / 1e9,\n",
    "                \"volume\": candle.volume,\n",
    "            }\n",
    "            for candle in candles\n",
    "        ]\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e72821ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_ml_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute the feature set used by the XGBoost model.\"\"\"\n",
    "\n",
    "    df = df.copy().reset_index(drop=True)\n",
    "    df[\"close\"] = df[\"close\"].astype(float)\n",
    "    df[\"logret\"] = np.log(df[\"close\"]).diff()\n",
    "    df[\"ret_1\"] = df[\"logret\"].shift(1)\n",
    "    for w in [3, 5, 10]:\n",
    "        df[f\"sma_{w}\"] = df[\"close\"].rolling(window=w).mean()\n",
    "        df[f\"std_{w}\"] = df[\"logret\"].rolling(window=w).std()\n",
    "    df[\"high\"] = df[\"high\"].astype(float)\n",
    "    df[\"low\"] = df[\"low\"].astype(float)\n",
    "    tr1 = df[\"high\"] - df[\"low\"]\n",
    "    tr2 = (df[\"high\"] - df[\"close\"].shift(1)).abs()\n",
    "    tr3 = (df[\"low\"] - df[\"close\"].shift(1)).abs()\n",
    "    df[\"tr\"] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    df[\"atr_14\"] = df[\"tr\"].rolling(14).mean()\n",
    "    feats = [\"ret_1\", \"sma_3\", \"sma_5\", \"sma_10\", \"std_3\", \"std_5\", \"std_10\", \"atr_14\"]\n",
    "    return df[feats]\n",
    "\n",
    "\n",
    "def load_xgb_model(model_path: str) -> \"xgb.Booster\":\n",
    "    \"\"\"Load a saved XGBoost model from file.\"\"\"\n",
    "\n",
    "    if xgb is None:\n",
    "        raise ImportError(\n",
    "            \"xgboost is not installed. Install it via `pip install xgboost` to use the ML inference pipeline.\"\n",
    "        )\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(model_path)\n",
    "    return booster\n",
    "\n",
    "\n",
    "def predict_ml(model: \"xgb.Booster\", feats_df: pd.DataFrame, return_proba: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"Run ML model inference on feature DataFrame.\"\"\"\n",
    "\n",
    "    dmatrix = xgb.DMatrix(feats_df)\n",
    "    probs = model.predict(dmatrix)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    idx_to_label = {0: \"down\", 1: \"flat\", 2: \"up\"}\n",
    "    labels = [idx_to_label.get(int(i), str(i)) for i in preds]\n",
    "    result: Dict[str, Any] = {\"indices\": preds.tolist(), \"labels\": labels}\n",
    "    if return_proba:\n",
    "        result[\"proba\"] = probs\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dedb7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cv_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute EMA and Bollinger band overlays for candlestick rendering.\"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"ema_10\"] = df[\"close\"].ewm(span=10).mean()\n",
    "    df[\"ema_20\"] = df[\"close\"].ewm(span=20).mean()\n",
    "    mid = df[\"close\"].rolling(20).mean()\n",
    "    std = df[\"close\"].rolling(20).std()\n",
    "    df[\"boll_up\"] = mid + 2 * std\n",
    "    df[\"boll_low\"] = mid - 2 * std\n",
    "    return df\n",
    "\n",
    "\n",
    "def render_candle_image(\n",
    "    sub_df: pd.DataFrame,\n",
    "    img_size: tuple = (8, 4),\n",
    "    dpi: int = 100,\n",
    "    use_jpg: bool = True,\n",
    "    style: Optional[Any] = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Render a single candlestick window into a NumPy RGB image.\"\"\"\n",
    "\n",
    "    if mpf is None or plt is None:\n",
    "        raise ImportError(\n",
    "            \"mplfinance and matplotlib must be installed to render candle images; install them via `pip install mplfinance matplotlib`\"\n",
    "        )\n",
    "\n",
    "    if style is None:\n",
    "        mc = mpf.make_marketcolors(up=\"lime\", down=\"red\", edge=\"white\", wick=\"white\", volume=\"gray\")\n",
    "        style = mpf.make_mpf_style(\n",
    "            base_mpf_style=\"nightclouds\",\n",
    "            facecolor=\"black\",\n",
    "            edgecolor=\"white\",\n",
    "            marketcolors=mc,\n",
    "            rc={\"axes.labelcolor\": \"white\", \"axes.edgecolor\": \"white\"},\n",
    "        )\n",
    "\n",
    "    fig, axes = mpf.plot(\n",
    "        sub_df,\n",
    "        type=\"candle\",\n",
    "        style=style,\n",
    "        volume=True,\n",
    "        figsize=img_size,\n",
    "        tight_layout=True,\n",
    "        show_nontrading=True,\n",
    "        returnfig=True,\n",
    "    )\n",
    "    for ax in axes:\n",
    "        ax.set_axis_off()\n",
    "        ax.grid(False)\n",
    "    if \"ema_10\" in sub_df.columns:\n",
    "        axes[0].plot(sub_df.index, sub_df[\"ema_10\"], color=\"deepskyblue\", linewidth=1)\n",
    "    if \"ema_20\" in sub_df.columns:\n",
    "        axes[0].plot(sub_df.index, sub_df[\"ema_20\"], color=\"orange\", linewidth=1)\n",
    "    if {\"boll_up\", \"boll_low\"}.issubset(sub_df.columns):\n",
    "        axes[0].plot(sub_df.index, sub_df[\"boll_up\"], color=\"gray\", linestyle=\"--\", linewidth=0.8)\n",
    "        axes[0].plot(sub_df.index, sub_df[\"boll_low\"], color=\"gray\", linestyle=\"--\", linewidth=0.8)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    buf = fig.canvas.buffer_rgba()\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = np.frombuffer(buf, dtype=np.uint8).reshape((h, w, 4))[..., :3]\n",
    "    plt.close(fig)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_cv_tensor(img: np.ndarray) -> \"torch.Tensor\":\n",
    "    \"\"\"Convert an RGB image array into a Torch tensor with normalization.\"\"\"\n",
    "\n",
    "    if torch is None or transforms is None:\n",
    "        raise ImportError(\"torch and torchvision must be installed to prepare image tensors\")\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "    return transform(img).unsqueeze(0)\n",
    "\n",
    "\n",
    "def load_cv_model(meta_path: str, model_path: str, device: Optional[str] = None) -> \"nn.Module\":\n",
    "    \"\"\"Reconstruct and load the CV model from saved state.\"\"\"\n",
    "\n",
    "    if timm is None or torch is None or nn is None:\n",
    "        raise ImportError(\"timm and torch must be installed to load the CV model\")\n",
    "\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with open(meta_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    label_to_idx: Dict[str, int] = meta[\"label_to_idx\"]\n",
    "    model_name: str = meta.get(\"model_name\", \"convnext_tiny\")\n",
    "    num_classes = len(label_to_idx)\n",
    "\n",
    "    backbone = timm.create_model(model_name, pretrained=False, num_classes=0, global_pool=\"avg\")\n",
    "    feat_dim = backbone.num_features  # type: ignore[attr-defined]\n",
    "    head = nn.Sequential(\n",
    "        nn.Linear(feat_dim, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, num_classes),\n",
    "    )\n",
    "    model = nn.Sequential(backbone, head)\n",
    "\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    state_dict = checkpoint[\"model_state\"] if isinstance(checkpoint, dict) and \"model_state\" in checkpoint else checkpoint\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_cv(\n",
    "    model: \"nn.Module\",\n",
    "    img_tensor: \"torch.Tensor\",\n",
    "    meta_path: str,\n",
    "    device: Optional[str] = None,\n",
    "    return_proba: bool = True,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run the CV model on a single image tensor.\"\"\"\n",
    "\n",
    "    if torch is None:\n",
    "        raise ImportError(\"torch must be installed to perform CV inference\")\n",
    "\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(img_tensor)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred_idx = probs.argmax(dim=1).cpu().numpy()\n",
    "        probs_np = probs.cpu().numpy()\n",
    "\n",
    "    with open(meta_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    idx_to_label = {v: k for k, v in meta[\"label_to_idx\"].items()}\n",
    "    labels = [idx_to_label.get(int(i), str(i)) for i in pred_idx]\n",
    "\n",
    "    result: Dict[str, Any] = {\"indices\": pred_idx.tolist(), \"labels\": labels}\n",
    "    if return_proba:\n",
    "        result[\"proba\"] = probs_np\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5c9120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def load_rl_agent(model_path: str, window_size: int, initial_balance: float) -> RLAgent:\n",
    "    \"\"\"Load and cache the PPO-based RL agent for inference.\"\"\"\n",
    "\n",
    "    return RLAgent(model_path=model_path, window_size=window_size, initial_balance=initial_balance)\n",
    "\n",
    "\n",
    "def prepare_rl_state(\n",
    "    df: pd.DataFrame,\n",
    "    window_size: int,\n",
    "    initial_balance: float,\n",
    "    position: int = 0,\n",
    "    equity: Optional[float] = None,\n",
    ") -> Tuple[pd.DataFrame, PortfolioState]:\n",
    "    \"\"\"Compute RL feature frame and latest portfolio state for action selection.\"\"\"\n",
    "\n",
    "    features = build_feature_frame(df)\n",
    "    if features.empty:\n",
    "        raise ValueError(\"Cannot build RL features from an empty DataFrame\")\n",
    "\n",
    "    pointer = len(features) - 1\n",
    "    state = PortfolioState(\n",
    "        pointer=pointer,\n",
    "        position=position,\n",
    "        equity=equity if equity is not None else initial_balance,\n",
    "    )\n",
    "    return features, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adf1277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_inference(\n",
    "    ticker: str = \"SBER\",\n",
    "    tf: CandleInterval = DEFAULT_TIMEFRAME,\n",
    "    days: int = 1,\n",
    "    lookback: int = 60,\n",
    "    ml_model_path: str = \"xgb_sber.model\",\n",
    "    cv_model_path: str = \"best_model.pth\",\n",
    "    meta_path: str = \"meta.json\",\n",
    "    token: Optional[str] = DEFAULT_TOKEN,\n",
    "    tz_name: str = \"Europe/Amsterdam\",\n",
    "    use_rl: bool = False,\n",
    "    rl_model_path: str = \"models/rl/checkpoints/ppo_trading_agent.zip\",\n",
    "    rl_window: int = 32,\n",
    "    initial_balance: float = 100_000.0,\n",
    "    portfolio_position: int = 0,\n",
    "    portfolio_equity: Optional[float] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run ML, CV, and optional RL models on the most recent candle data.\"\"\"\n",
    "\n",
    "    tz = pytz.timezone(tz_name)\n",
    "    df_candles = fetch_tinkoff_candles(token or \"\", ticker, days=days, interval=tf, tz=tz)\n",
    "    if df_candles.empty:\n",
    "        raise RuntimeError(\"No candle data available for inference\")\n",
    "    df_candles = df_candles.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "    ml_model = load_xgb_model(ml_model_path)\n",
    "    feats_df = compute_ml_features(df_candles).dropna()\n",
    "    ml_result = predict_ml(ml_model, feats_df, return_proba=True)\n",
    "\n",
    "    df_feat = add_cv_features(df_candles)\n",
    "    if len(df_feat) < lookback:\n",
    "        raise ValueError(\n",
    "            f\"Not enough candles ({len(df_feat)}) for lookback={lookback}. Increase history length or decrease lookback.\"\n",
    "        )\n",
    "    sub = df_feat.iloc[-lookback:].copy()\n",
    "    sub[\"time\"] = pd.to_datetime(sub[\"time\"])\n",
    "    sub = sub.set_index(\"time\")\n",
    "    img = render_candle_image(sub, img_size=(8, 4), dpi=100, use_jpg=True)\n",
    "    img_tensor = prepare_cv_tensor(img)\n",
    "    cv_model = load_cv_model(meta_path, cv_model_path)\n",
    "    cv_result = predict_cv(cv_model, img_tensor, meta_path, return_proba=True)\n",
    "\n",
    "    rl_action = None\n",
    "    rl_action_label = None\n",
    "    rl_state = None\n",
    "    rl_features = None\n",
    "    if use_rl:\n",
    "        agent = load_rl_agent(rl_model_path, rl_window, initial_balance)\n",
    "        rl_features, rl_state = prepare_rl_state(\n",
    "            df_candles,\n",
    "            window_size=rl_window,\n",
    "            initial_balance=initial_balance,\n",
    "            position=portfolio_position,\n",
    "            equity=portfolio_equity if portfolio_equity is not None else initial_balance,\n",
    "        )\n",
    "        rl_action, rl_action_label = agent.get_action(rl_features, rl_state)\n",
    "\n",
    "    result: Dict[str, Any] = {\"ml_preds\": ml_result, \"cv_preds\": cv_result, \"df_candles\": df_candles}\n",
    "    if use_rl:\n",
    "        result.update(\n",
    "            {\n",
    "                \"rl_action\": rl_action,\n",
    "                \"rl_action_label\": rl_action_label,\n",
    "                \"rl_portfolio_state\": rl_state,\n",
    "                \"rl_features\": rl_features.tail(rl_window) if rl_features is not None else None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be7421d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14448\\384533235.py:30: UserWarning: [14:36:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1511: Unknown file format: `model`. Using UBJSON (`ubj`) as a guess.\n",
      "  booster.load_model(model_path)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models\\\\RL\\\\checkpoints\\\\ppo_trading_agent.zip.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m portfolio_position = \u001b[32m0\u001b[39m\n\u001b[32m     14\u001b[39m portfolio_equity = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m full_result = \u001b[43mrun_full_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdays\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlookback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlookback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mml_model_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mml_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv_model_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEFAULT_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtz_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEurope/Amsterdam\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_rl\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_rl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrl_model_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrl_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrl_window\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrl_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_balance\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_balance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mportfolio_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mportfolio_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mportfolio_equity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mportfolio_equity\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[33m\"\u001b[39m\u001b[33m# Краткий вывод результатов\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mML prediction:\u001b[39m\u001b[33m\"\u001b[39m, full_result[\u001b[33m\"\u001b[39m\u001b[33mml_preds\u001b[39m\u001b[33m\"\u001b[39m] )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mrun_full_inference\u001b[39m\u001b[34m(ticker, tf, days, lookback, ml_model_path, cv_model_path, meta_path, token, tz_name, use_rl, rl_model_path, rl_window, initial_balance, portfolio_position, portfolio_equity)\u001b[39m\n\u001b[32m     46\u001b[39m rl_features = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_rl:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     agent = \u001b[43mload_rl_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrl_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrl_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_balance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     rl_features, rl_state = prepare_rl_state(\n\u001b[32m     50\u001b[39m         df_candles,\n\u001b[32m     51\u001b[39m         window_size=rl_window,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m         equity=portfolio_equity \u001b[38;5;28;01mif\u001b[39;00m portfolio_equity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m initial_balance,\n\u001b[32m     55\u001b[39m     )\n\u001b[32m     56\u001b[39m     rl_action, rl_action_label = agent.get_action(rl_features, rl_state)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_rl_agent\u001b[39m\u001b[34m(model_path, window_size, initial_balance)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;129m@lru_cache\u001b[39m(maxsize=\u001b[32m1\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_rl_agent\u001b[39m(model_path: \u001b[38;5;28mstr\u001b[39m, window_size: \u001b[38;5;28mint\u001b[39m, initial_balance: \u001b[38;5;28mfloat\u001b[39m) -> RLAgent:\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load and cache the PPO-based RL agent for inference.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRLAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_balance\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_balance\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Code\\Trade-bot\\app\\RL\\agent.py:91\u001b[39m, in \u001b[36mRLAgent.__init__\u001b[39m\u001b[34m(self, model_path, window_size, initial_balance)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     86\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     87\u001b[39m     model_path: \u001b[38;5;28mstr\u001b[39m | Path,\n\u001b[32m     88\u001b[39m     window_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m32\u001b[39m,\n\u001b[32m     89\u001b[39m     initial_balance: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m100_000.0\u001b[39m,\n\u001b[32m     90\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[43mPPO\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mself\u001b[39m.window_size = window_size\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m.initial_balance = initial_balance\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Code\\Quant\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:681\u001b[39m, in \u001b[36mBaseAlgorithm.load\u001b[39m\u001b[34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m     get_system_info()\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m data, params, pytorch_variables = \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mNo data found in the saved file\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mNo params found in the saved file\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Code\\Quant\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:403\u001b[39m, in \u001b[36mload_from_zip_file\u001b[39m\u001b[34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_zip_file\u001b[39m(\n\u001b[32m    377\u001b[39m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib.Path, io.BufferedIOBase],\n\u001b[32m    378\u001b[39m     load_data: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     print_system_info: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    385\u001b[39m \u001b[33;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[32m    386\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    401\u001b[39m \u001b[33;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     file = \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[32m    406\u001b[39m     device = get_device(device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\functools.py:909\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    907\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Code\\Quant\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:240\u001b[39m, in \u001b[36mopen_path_str\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;129m@open_path\u001b[39m.register(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> io.BufferedIOBase:\n\u001b[32m    227\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[33;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[33;03m    that the path exists.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    238\u001b[39m \u001b[33;03m    :return:\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Code\\Quant\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:291\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    285\u001b[39m         path.parent.mkdir(exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m, parents=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# if opening was successful uses the open_path() function\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Code\\Quant\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:272\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    270\u001b[39m             path, suffix = newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\Desktop\\Code\\Quant\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\save_util.py:264\u001b[39m, in \u001b[36mopen_path_pathlib\u001b[39m\u001b[34m(path, mode, verbose, suffix)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m open_path(\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, mode, verbose, suffix)\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    266\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:1044\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1043\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m io.open(\u001b[38;5;28mself\u001b[39m, mode, buffering, encoding, errors, newline)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'models\\\\RL\\\\checkpoints\\\\ppo_trading_agent.zip.zip'"
     ]
    }
   ],
   "source": [
    "# Полный прогон инференса\\n\",\n",
    "ticker = \"SBER\"\n",
    "tf = DEFAULT_TIMEFRAME\n",
    "days = 1\n",
    "lookback = 60\n",
    "ml_model_path = \"xgb_sber.model\"\n",
    "cv_model_path = \"best_model.pth\"\n",
    "meta_path = \"meta.json\"\n",
    "use_rl = True  # при необходимости включите RL\n",
    "rl_model_path = \"models/RL/checkpoints/ppo_trading_agent.zip\"\n",
    "rl_window = 32\n",
    "initial_balance = 100_000.0\n",
    "portfolio_position = 0\n",
    "portfolio_equity = None\n",
    "full_result = run_full_inference(\n",
    "    ticker=ticker,\n",
    "    tf=tf,\n",
    "    days=days,\n",
    "    lookback=lookback,\n",
    "    ml_model_path=ml_model_path,\n",
    "    cv_model_path=cv_model_path,\n",
    "    meta_path=meta_path,\n",
    "    token=DEFAULT_TOKEN,\n",
    "    tz_name=\"Europe/Amsterdam\",\n",
    "    use_rl=use_rl,\n",
    "    rl_model_path=rl_model_path,\n",
    "    rl_window=rl_window,\n",
    "    initial_balance=initial_balance,\n",
    "    portfolio_position=portfolio_position,\n",
    "    portfolio_equity=portfolio_equity\n",
    ")\n",
    "\n",
    "\"# Краткий вывод результатов\"\n",
    "print(\"ML prediction:\", full_result[\"ml_preds\"] )\n",
    "print(\"CV prediction:\", full_result[\"cv_preds\"] )\n",
    "if use_rl:\n",
    "    print(\"RL action label:\", full_result.get(\"rl_action_label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039ed24e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
