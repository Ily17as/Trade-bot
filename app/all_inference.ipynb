{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52fdf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m     mpf = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     45\u001b[39m     plt = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mRL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_feature_frame\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mRL\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RLAgent\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mRL\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PortfolioState\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "\"\"\"Shared inference utilities extracted from the original notebook.\n",
    "\n",
    "This module centralizes the ML, CV, and optional RL inference steps that were\n",
    "previously defined inside ``app/inference_pipeline.ipynb`` so that they can be\n",
    "imported and reused without executing notebook cells.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from functools import lru_cache\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from dotenv import load_dotenv\n",
    "from tinkoff.invest import CandleInterval, Client\n",
    "\n",
    "try:  # ML\n",
    "    import xgboost as xgb\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    xgb = None  # type: ignore\n",
    "\n",
    "try:  # CV\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from torchvision import transforms\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    torch = None  # type: ignore\n",
    "    nn = None  # type: ignore\n",
    "    transforms = None  # type: ignore\n",
    "\n",
    "try:  # CV backbone\n",
    "    import timm\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    timm = None  # type: ignore\n",
    "\n",
    "try:  # Candle rendering\n",
    "    import mplfinance as mpf\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:  # pragma: no cover - optional dependency\n",
    "    mpf = None  # type: ignore\n",
    "    plt = None  # type: ignore\n",
    "\n",
    "from models.RL import build_feature_frame\n",
    "from models.RL.agent import RLAgent\n",
    "from models.RL.env import PortfolioState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b328b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "DEFAULT_TOKEN = os.getenv(\"TINKOFF_TOKEN\")\n",
    "DEFAULT_TZ = pytz.timezone(\"Europe/Moscow\")\n",
    "DEFAULT_TIMEFRAME = CandleInterval.CANDLE_INTERVAL_5_MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce68445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tinkoff_candles(\n",
    "    token: str,\n",
    "    ticker: str,\n",
    "    days: int = 1,\n",
    "    interval: CandleInterval = DEFAULT_TIMEFRAME,\n",
    "    tz: pytz.BaseTzInfo = DEFAULT_TZ,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Download OHLCV candles from the Tinkoff Invest API.\"\"\"\n",
    "\n",
    "    if not token:\n",
    "        raise RuntimeError(\"TINKOFF_TOKEN is required to fetch candles\")\n",
    "\n",
    "    from tinkoff.invest.services import InstrumentsService  # lazy import\n",
    "    from tinkoff.invest.utils import now\n",
    "\n",
    "    with Client(token) as client:\n",
    "        instruments: InstrumentsService = client.instruments\n",
    "        shares = instruments.shares().instruments\n",
    "        figi: Optional[str] = None\n",
    "        for share in shares:\n",
    "            if share.ticker.upper() == ticker.upper():\n",
    "                figi = share.figi\n",
    "                break\n",
    "        if not figi:\n",
    "            raise RuntimeError(f\"FIGI for {ticker} not found\")\n",
    "\n",
    "        end = now()\n",
    "        start = end - timedelta(days=days)\n",
    "        candles = client.get_all_candles(figi=figi, from_=start, to=end, interval=interval)\n",
    "\n",
    "        data = [\n",
    "            {\n",
    "                \"time\": candle.time.astimezone(tz),\n",
    "                \"open\": candle.open.units + candle.open.nano / 1e9,\n",
    "                \"high\": candle.high.units + candle.high.nano / 1e9,\n",
    "                \"low\": candle.low.units + candle.low.nano / 1e9,\n",
    "                \"close\": candle.close.units + candle.close.nano / 1e9,\n",
    "                \"volume\": candle.volume,\n",
    "            }\n",
    "            for candle in candles\n",
    "        ]\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e72821ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_ml_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute the feature set used by the XGBoost model.\"\"\"\n",
    "\n",
    "    df = df.copy().reset_index(drop=True)\n",
    "    df[\"close\"] = df[\"close\"].astype(float)\n",
    "    df[\"logret\"] = np.log(df[\"close\"]).diff()\n",
    "    df[\"ret_1\"] = df[\"logret\"].shift(1)\n",
    "    for w in [3, 5, 10]:\n",
    "        df[f\"sma_{w}\"] = df[\"close\"].rolling(window=w).mean()\n",
    "        df[f\"std_{w}\"] = df[\"logret\"].rolling(window=w).std()\n",
    "    df[\"high\"] = df[\"high\"].astype(float)\n",
    "    df[\"low\"] = df[\"low\"].astype(float)\n",
    "    tr1 = df[\"high\"] - df[\"low\"]\n",
    "    tr2 = (df[\"high\"] - df[\"close\"].shift(1)).abs()\n",
    "    tr3 = (df[\"low\"] - df[\"close\"].shift(1)).abs()\n",
    "    df[\"tr\"] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    df[\"atr_14\"] = df[\"tr\"].rolling(14).mean()\n",
    "    feats = [\"ret_1\", \"sma_3\", \"sma_5\", \"sma_10\", \"std_3\", \"std_5\", \"std_10\", \"atr_14\"]\n",
    "    return df[feats]\n",
    "\n",
    "\n",
    "def load_xgb_model(model_path: str) -> \"xgb.Booster\":\n",
    "    \"\"\"Load a saved XGBoost model from file.\"\"\"\n",
    "\n",
    "    if xgb is None:\n",
    "        raise ImportError(\n",
    "            \"xgboost is not installed. Install it via `pip install xgboost` to use the ML inference pipeline.\"\n",
    "        )\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(model_path)\n",
    "    return booster\n",
    "\n",
    "\n",
    "def predict_ml(model: \"xgb.Booster\", feats_df: pd.DataFrame, return_proba: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"Run ML model inference on feature DataFrame.\"\"\"\n",
    "\n",
    "    dmatrix = xgb.DMatrix(feats_df)\n",
    "    probs = model.predict(dmatrix)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    idx_to_label = {0: \"down\", 1: \"flat\", 2: \"up\"}\n",
    "    labels = [idx_to_label.get(int(i), str(i)) for i in preds]\n",
    "    result: Dict[str, Any] = {\"indices\": preds.tolist(), \"labels\": labels}\n",
    "    if return_proba:\n",
    "        result[\"proba\"] = probs\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedb7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cv_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute EMA and Bollinger band overlays for candlestick rendering.\"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"ema_10\"] = df[\"close\"].ewm(span=10).mean()\n",
    "    df[\"ema_20\"] = df[\"close\"].ewm(span=20).mean()\n",
    "    mid = df[\"close\"].rolling(20).mean()\n",
    "    std = df[\"close\"].rolling(20).std()\n",
    "    df[\"boll_up\"] = mid + 2 * std\n",
    "    df[\"boll_low\"] = mid - 2 * std\n",
    "    return df\n",
    "\n",
    "\n",
    "def render_candle_image(\n",
    "    sub_df: pd.DataFrame,\n",
    "    img_size: tuple = (8, 4),\n",
    "    dpi: int = 100,\n",
    "    use_jpg: bool = True,\n",
    "    style: Optional[Any] = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Render a single candlestick window into a NumPy RGB image.\"\"\"\n",
    "\n",
    "    if mpf is None or plt is None:\n",
    "        raise ImportError(\n",
    "            \"mplfinance and matplotlib must be installed to render candle images; install them via `pip install mplfinance matplotlib`\"\n",
    "        )\n",
    "\n",
    "    if style is None:\n",
    "        mc = mpf.make_marketcolors(up=\"lime\", down=\"red\", edge=\"white\", wick=\"white\", volume=\"gray\")\n",
    "        style = mpf.make_mpf_style(\n",
    "            base_mpf_style=\"nightclouds\",\n",
    "            facecolor=\"black\",\n",
    "            edgecolor=\"white\",\n",
    "            marketcolors=mc,\n",
    "            rc={\"axes.labelcolor\": \"white\", \"axes.edgecolor\": \"white\"},\n",
    "        )\n",
    "\n",
    "    fig, axes = mpf.plot(\n",
    "        sub_df,\n",
    "        type=\"candle\",\n",
    "        style=style,\n",
    "        volume=True,\n",
    "        figsize=img_size,\n",
    "        tight_layout=True,\n",
    "        show_nontrading=True,\n",
    "        returnfig=True,\n",
    "    )\n",
    "    for ax in axes:\n",
    "        ax.set_axis_off()\n",
    "        ax.grid(False)\n",
    "    if \"ema_10\" in sub_df.columns:\n",
    "        axes[0].plot(sub_df.index, sub_df[\"ema_10\"], color=\"deepskyblue\", linewidth=1)\n",
    "    if \"ema_20\" in sub_df.columns:\n",
    "        axes[0].plot(sub_df.index, sub_df[\"ema_20\"], color=\"orange\", linewidth=1)\n",
    "    if {\"boll_up\", \"boll_low\"}.issubset(sub_df.columns):\n",
    "        axes[0].plot(sub_df.index, sub_df[\"boll_up\"], color=\"gray\", linestyle=\"--\", linewidth=0.8)\n",
    "        axes[0].plot(sub_df.index, sub_df[\"boll_low\"], color=\"gray\", linestyle=\"--\", linewidth=0.8)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    buf = fig.canvas.buffer_rgba()\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    img = np.frombuffer(buf, dtype=np.uint8).reshape((h, w, 4))[..., :3]\n",
    "    plt.close(fig)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_cv_tensor(img: np.ndarray) -> \"torch.Tensor\":\n",
    "    \"\"\"Convert an RGB image array into a Torch tensor with normalization.\"\"\"\n",
    "\n",
    "    if torch is None or transforms is None:\n",
    "        raise ImportError(\"torch and torchvision must be installed to prepare image tensors\")\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "    return transform(img).unsqueeze(0)\n",
    "\n",
    "\n",
    "def load_cv_model(meta_path: str, model_path: str, device: Optional[str] = None) -> \"nn.Module\":\n",
    "    \"\"\"Reconstruct and load the CV model from saved state.\"\"\"\n",
    "\n",
    "    if timm is None or torch is None or nn is None:\n",
    "        raise ImportError(\"timm and torch must be installed to load the CV model\")\n",
    "\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with open(meta_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    label_to_idx: Dict[str, int] = meta[\"label_to_idx\"]\n",
    "    model_name: str = meta.get(\"model_name\", \"convnext_tiny\")\n",
    "    num_classes = len(label_to_idx)\n",
    "\n",
    "    backbone = timm.create_model(model_name, pretrained=False, num_classes=0, global_pool=\"avg\")\n",
    "    feat_dim = backbone.num_features  # type: ignore[attr-defined]\n",
    "    head = nn.Sequential(\n",
    "        nn.Linear(feat_dim, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(512, num_classes),\n",
    "    )\n",
    "    model = nn.Sequential(backbone, head)\n",
    "\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    state_dict = checkpoint[\"model_state\"] if isinstance(checkpoint, dict) and \"model_state\" in checkpoint else checkpoint\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_cv(\n",
    "    model: \"nn.Module\",\n",
    "    img_tensor: \"torch.Tensor\",\n",
    "    meta_path: str,\n",
    "    device: Optional[str] = None,\n",
    "    return_proba: bool = True,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run the CV model on a single image tensor.\"\"\"\n",
    "\n",
    "    if torch is None:\n",
    "        raise ImportError(\"torch must be installed to perform CV inference\")\n",
    "\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(img_tensor)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred_idx = probs.argmax(dim=1).cpu().numpy()\n",
    "        probs_np = probs.cpu().numpy()\n",
    "\n",
    "    with open(meta_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    idx_to_label = {v: k for k, v in meta[\"label_to_idx\"].items()}\n",
    "    labels = [idx_to_label.get(int(i), str(i)) for i in pred_idx]\n",
    "\n",
    "    result: Dict[str, Any] = {\"indices\": pred_idx.tolist(), \"labels\": labels}\n",
    "    if return_proba:\n",
    "        result[\"proba\"] = probs_np\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c9120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def load_rl_agent(model_path: str, window_size: int, initial_balance: float) -> RLAgent:\n",
    "    \"\"\"Load and cache the PPO-based RL agent for inference.\"\"\"\n",
    "\n",
    "    return RLAgent(model_path=model_path, window_size=window_size, initial_balance=initial_balance)\n",
    "\n",
    "\n",
    "def prepare_rl_state(\n",
    "    df: pd.DataFrame,\n",
    "    window_size: int,\n",
    "    initial_balance: float,\n",
    "    position: int = 0,\n",
    "    equity: Optional[float] = None,\n",
    ") -> Tuple[pd.DataFrame, PortfolioState]:\n",
    "    \"\"\"Compute RL feature frame and latest portfolio state for action selection.\"\"\"\n",
    "\n",
    "    features = build_feature_frame(df)\n",
    "    if features.empty:\n",
    "        raise ValueError(\"Cannot build RL features from an empty DataFrame\")\n",
    "\n",
    "    pointer = len(features) - 1\n",
    "    state = PortfolioState(\n",
    "        pointer=pointer,\n",
    "        position=position,\n",
    "        equity=equity if equity is not None else initial_balance,\n",
    "    )\n",
    "    return features, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf1277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_inference(\n",
    "    ticker: str = \"SBER\",\n",
    "    tf: CandleInterval = DEFAULT_TIMEFRAME,\n",
    "    days: int = 1,\n",
    "    lookback: int = 60,\n",
    "    ml_model_path: str = \"xgb_sber.model\",\n",
    "    cv_model_path: str = \"best_model.pth\",\n",
    "    meta_path: str = \"meta.json\",\n",
    "    token: Optional[str] = DEFAULT_TOKEN,\n",
    "    tz_name: str = \"Europe/Amsterdam\",\n",
    "    use_rl: bool = False,\n",
    "    rl_model_path: str = \"models/RL/checkpoints/ppo_trading_agent.zip\",\n",
    "    rl_window: int = 32,\n",
    "    initial_balance: float = 100_000.0,\n",
    "    portfolio_position: int = 0,\n",
    "    portfolio_equity: Optional[float] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run ML, CV, and optional RL models on the most recent candle data.\"\"\"\n",
    "\n",
    "    tz = pytz.timezone(tz_name)\n",
    "    df_candles = fetch_tinkoff_candles(token or \"\", ticker, days=days, interval=tf, tz=tz)\n",
    "    if df_candles.empty:\n",
    "        raise RuntimeError(\"No candle data available for inference\")\n",
    "    df_candles = df_candles.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "    ml_model = load_xgb_model(ml_model_path)\n",
    "    feats_df = compute_ml_features(df_candles).dropna()\n",
    "    ml_result = predict_ml(ml_model, feats_df, return_proba=True)\n",
    "\n",
    "    df_feat = add_cv_features(df_candles)\n",
    "    if len(df_feat) < lookback:\n",
    "        raise ValueError(\n",
    "            f\"Not enough candles ({len(df_feat)}) for lookback={lookback}. Increase history length or decrease lookback.\"\n",
    "        )\n",
    "    sub = df_feat.iloc[-lookback:].copy()\n",
    "    sub[\"time\"] = pd.to_datetime(sub[\"time\"])\n",
    "    sub = sub.set_index(\"time\")\n",
    "    img = render_candle_image(sub, img_size=(8, 4), dpi=100, use_jpg=True)\n",
    "    img_tensor = prepare_cv_tensor(img)\n",
    "    cv_model = load_cv_model(meta_path, cv_model_path)\n",
    "    cv_result = predict_cv(cv_model, img_tensor, meta_path, return_proba=True)\n",
    "\n",
    "    rl_action = None\n",
    "    rl_action_label = None\n",
    "    rl_state = None\n",
    "    rl_features = None\n",
    "    if use_rl:\n",
    "        agent = load_rl_agent(rl_model_path, rl_window, initial_balance)\n",
    "        rl_features, rl_state = prepare_rl_state(\n",
    "            df_candles,\n",
    "            window_size=rl_window,\n",
    "            initial_balance=initial_balance,\n",
    "            position=portfolio_position,\n",
    "            equity=portfolio_equity if portfolio_equity is not None else initial_balance,\n",
    "        )\n",
    "        rl_action, rl_action_label = agent.get_action(rl_features, rl_state)\n",
    "\n",
    "    result: Dict[str, Any] = {\"ml_preds\": ml_result, \"cv_preds\": cv_result, \"df_candles\": df_candles}\n",
    "    if use_rl:\n",
    "        result.update(\n",
    "            {\n",
    "                \"rl_action\": rl_action,\n",
    "                \"rl_action_label\": rl_action_label,\n",
    "                \"rl_portfolio_state\": rl_state,\n",
    "                \"rl_features\": rl_features.tail(rl_window) if rl_features is not None else None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7421d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
